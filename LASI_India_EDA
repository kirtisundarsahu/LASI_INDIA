#Check and understand working directory
import os
import pandas as pd
import numpy as np
os.getcwd()

#import data 
#df = pd.read_stata('3_LASI_W1_Individual_data.dta') #STATA FILE
df1 = pd.read_csv('Individual_data.csv',encoding='latin1') 
#view data
df1.head()
#list column names
print(list(df1.columns))

#Subset data by column name#####

df2=df1.filter(regex='dm')
#select required columns by number 
df1.iloc[:, [1, 2, 5]]
#select required columns by name
df[['width’, 'length’, 'species']]
#Drop columns from DataFrame
df.drop(columns=['Length’, 'Height'])
#select specific rows
rslt_df = df1.loc[df1['mh021'] <= 1]
#view data
df2.head()
#view variable types
df2.dtypes
df.dtypes.value_counts() #count no of variables from each type
#convert one typeof variable to others
df2["dm010"] = df2["dm010"].astype("category")
#convert typeof variable to others within a selected dataframe
for c in df2.columns:
  if df2[c].dtype == 'int64':
    try:
        df2[c] = df2[c].astype('category')
    except:
        print('Column',' ',c,' cannot be converted to category.')
df2.dtypes
#change one value in a row to another value 
df1['mh021']=np.where(df1['mh021'] =='basic.9y', 'Basic', df1['education'])

#create new column
df["new"]=df["var1"]+df["var2"]


#Missing data handling
#calculate number/proportion of missing data by variable
data_final.isnull().sum()
data_final.isnull().sum()/len(data_final)*100
#Ignore
df1=df1.dropna()
#fill with certain number
df1=df1.fillna(0)
#impute with median or mode by variable
train['Item_Weight'].fillna(train['Item_Weight'].median(), inplace=True)
train['Outlet_Size'].fillna(train['Outlet_Size'].mode()[0], inplace=True)
#impute with certain number
from sklearn.preprocessing import Imputer
imp = Imputer(missing_values=0, strategy= "mean", axis=0)

#filter by proportion of missing data

a=data_final.isnull().sum()/len(data_final)*100

variables = data_final.columns
newvariable = [ ]
#for first 12 varaibles 
for i in range(0,12):
    if a[i]<=20:   #setting the threshold as 20%
        newvariable.append(variables[i])
#for all variables
for i in range (len(variables)):
    if a[i]<=20:   #setting the threshold as 20%
        newvariable.append(variables[i])

#claculate variance of all the varaibles
df.var()

#filter by variance less than certain point

numeric = train[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']]
var = numeric.var()
numeric = numeric.columns
variable = [ ]
for i in range(0,len(var)):
    if var[i]>=10:   #setting the threshold as 10%
       variable.append(numeric[i+1])

#EDA
#UNIVARIATE DATA ANALYSIS
#CATEGORICAL DATA
print(df.columns.values)
df1['dm010'].unique()
df1['dm010'].value_counts()
sns.countplot(x='dm010', data=df1, palette='hls')
#Continous data
df1["dm007"].mean()
df1["dm007"].describe()

#Continous data visualization
df1.dm007.hist()
plt.title('Histogram of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.savefig('hist_age')

#bivariate analysis- cat/cat
pd.crosstab(df1.dm002,df1.dm003, normalize='index')\
    .round(4)*100
#bivariate analysis- cat/cat-visualization
%matplotlib inline
pd.crosstab(df1.dm002,df1.dm003).plot(kind='bar')
plt.title('********')
plt.xlabel('%%')
plt.ylabel('SSSSSSSS')
plt.savefig('@@@@@')

df1["dm007"].groupby(df1["dm005"]).mean()

#bivariate analysis- cont/cont
corrMatrix = df1.corr()
print (corrMatrix)

#data visualization-scatter plot- cont/cont 
df1.plot.scatter(x='dm005',y='dm007')

